{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition: Reddit Scraping\n",
    "\n",
    "In this exercise, we will search a query (e.g., \"data science\") on the old Reddit interface (https://www.old.reddit.com/). We will then grab the url (e.g., https://old.reddit.com/search?q=data+science) of the search page and scrap the returned posts. The reason for using the old Reddit interface is that the html tags are user-friendly. We will focus on extracting title, author, author's profile, subreddit, tag, timestamp, number of votes, and number of comments. \n",
    "<img src=\"../images/reddit_search.png\" />\n",
    "\n",
    "\n",
    "\n",
    "* You are free to use your own query string. \n",
    "* On the search page, a set of subreddits are shown. Ignore these subreddits and focus on extracting Reddit posts. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 1:** Fetch the page and create a soup object using Beautiful soup library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for activity 1 goes here..\n",
    "#---------------------------------------\n",
    "\n",
    "#import the library to query a website\n",
    "import requests\n",
    "# import Beautiful soup library to access \n",
    "# functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#import pandas to convert list to data frame\n",
    "import pandas as pd\n",
    "#imprt numpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "headers = {'User-Agent': 'MyAPP/1.0'}  \n",
    "# this will make sure our query is comming from a browser and it's not a bot\n",
    "\n",
    "\n",
    "# specify the url\n",
    "url = 'https://old.reddit.com/search?q=data+science'\n",
    "\n",
    "# Open website URL and return the html to the variable 'response'\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Parse the html in the 'response' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(response.text, \"html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {'class': 'search-result'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a list of all the html objects \n",
    "\n",
    "posts = soup.find_all('div', class_=\"search-result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_1 = posts[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2:** Extract the titles and URLs of the retrieved posts from the soup and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science even at mature companies can be a mixed bag.\n",
      "Who are your data science heroes?\n",
      "College Professor in Data Science Course Just Said That Functional Programming Is Better Than OOP, Does He Have a Point?\n",
      "Do you use OOP in your daily data science work?\n",
      "The Key Word in Data Science is Science, not Data\n",
      "I built an interactive map to help people self-teaching Data Science online. It's like a skill tree for Data Science!\n",
      "Ethics of a data science project I am undertaking\n",
      "What data science skills do you see as in-demand given evolution of data science field in last few years?\n",
      "So I, a data science noob, ran sentiment analysis on as much BTS MVs on r/kpop I could find...\n",
      "How I use Data Science to Trade Options Around Earnings\n",
      "Why do people look down on data science work and “computer” work in general?\n",
      "Data Science for the Good of Society: are there realistic employment options?\n",
      "I am interested in creating a group of new comers and intermediate Data science and ML practitioners just to help each other and collaborate for various projects and discussion.\n",
      "MIT to Host First Citizen Data Science Summit on September 20 | Register For Free\n",
      "My Notion layout to manage full-time Physiology and CS studies, part-time data science job, and volunteering\n",
      "Canoo Poaches Lockheed Martin's Manager of Data Systems Architecture, Data Management, Business Intelligence + Data Science (Analytics)\n",
      "Feeling completely lost (Coursera Data Science with R)\n",
      "Is Data Science useful in GNC teams (or other engineering teams too)? Is there a way to combine DS and GNC?\n",
      "FYI: If You're New to the Industry, the Data Science Job Market is Saturated\n",
      "How I use Data Science to Trade Options Around Earnings\n",
      "Going back to school to get my masters in the next few years. I'd like to work as a data scientist eventually. Anyone know if it'd be better to get a degree in data science versus statistics?\n",
      "Learn \"Data Science for Marketing Analysis\" FREE!\n"
     ]
    }
   ],
   "source": [
    "# Titles\n",
    "\n",
    "Title = []\n",
    "\n",
    "for post in posts[3:]:\n",
    "    content = post.find(\"a\", class_=\"search-title\",text=True)\n",
    "    Title.append(content.text)\n",
    "    print(content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/r/datascience/comments/pu1y72/data_science_even_at_mature_companies_can_be_a/\n",
      "/r/datascience/comments/pq44jp/who_are_your_data_science_heroes/\n",
      "/r/datascience/comments/ppntvz/college_professor_in_data_science_course_just/\n",
      "/r/datascience/comments/pkw92b/do_you_use_oop_in_your_daily_data_science_work/\n",
      "/r/datascience/comments/p7hpd9/the_key_word_in_data_science_is_science_not_data/\n",
      "/r/learndatascience/comments/pjplux/i_built_an_interactive_map_to_help_people/\n",
      "/r/datascience/comments/prrou1/ethics_of_a_data_science_project_i_am_undertaking/\n",
      "/r/datascience/comments/pj3dls/what_data_science_skills_do_you_see_as_indemand/\n",
      "/r/kpopthoughts/comments/plyyes/so_i_a_data_science_noob_ran_sentiment_analysis/\n",
      "/r/wallstreetbets/comments/psyjv5/how_i_use_data_science_to_trade_options_around/\n",
      "/r/datascience/comments/pmb7a3/why_do_people_look_down_on_data_science_work_and/\n",
      "/r/datascience/comments/p5mzc3/data_science_for_the_good_of_society_are_there/\n",
      "/r/datascience/comments/oy2vfu/i_am_interested_in_creating_a_group_of_new_comers/\n",
      "/r/datascience/comments/pq0wpu/mit_to_host_first_citizen_data_science_summit_on/\n",
      "/r/Notion/comments/ppqeul/my_notion_layout_to_manage_fulltime_physiology/\n",
      "/r/canoo/comments/psobf0/canoo_poaches_lockheed_martins_manager_of_data/\n",
      "/r/rstats/comments/psjo37/feeling_completely_lost_coursera_data_science/\n",
      "/r/AerospaceEngineering/comments/po2e8z/is_data_science_useful_in_gnc_teams_or_other/\n",
      "/r/datascience/comments/ons0gh/fyi_if_youre_new_to_the_industry_the_data_science/\n",
      "/r/smallstreetbets/comments/prg7c8/how_i_use_data_science_to_trade_options_around/\n",
      "/r/analytics/comments/pqxmz5/going_back_to_school_to_get_my_masters_in_the/\n",
      "/r/learndatascience/comments/pug81r/learn_data_science_for_marketing_analysis_free/\n"
     ]
    }
   ],
   "source": [
    "# Links\n",
    "\n",
    "URL = []\n",
    "\n",
    "for post in posts[3:]:\n",
    "    link = post.find(\"a\")\n",
    "    URL.append(link.get('href'))\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 3:** Extract the author ids and their profile links from the retrieved posts and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__compactsupport__\n",
      "GravityAI\n",
      "Illustrious_Ice_5022\n",
      "rightheart\n",
      "yoi12321\n",
      "InstinctiveDoubt\n",
      "productive_guy123\n",
      "svyas\n",
      "palebabbu\n",
      "nema31lebowski\n",
      "ogretronz\n",
      "saindoja\n",
      "yaakarsh1011\n",
      "saik2363\n",
      "VictorChen1\n",
      "MisterInvicta\n",
      "hyperxenophiliac\n",
      "TheLSales\n",
      "aznpersuazion\n",
      "kribz666\n",
      "fu11m3ta1\n",
      "kunal_packtpub\n"
     ]
    }
   ],
   "source": [
    "# author\n",
    "\n",
    "Author = []\n",
    "\n",
    "for post in posts[3:]:\n",
    "    author = post.find(\"a\", class_=\"author\",text=True)\n",
    "    Author.append(author.text)\n",
    "    print(author.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://old.reddit.com/user/__compactsupport__\n",
      "https://old.reddit.com/user/GravityAI\n",
      "https://old.reddit.com/user/Illustrious_Ice_5022\n",
      "https://old.reddit.com/user/rightheart\n",
      "https://old.reddit.com/user/yoi12321\n",
      "https://old.reddit.com/user/InstinctiveDoubt\n",
      "https://old.reddit.com/user/productive_guy123\n",
      "https://old.reddit.com/user/svyas\n",
      "https://old.reddit.com/user/palebabbu\n",
      "https://old.reddit.com/user/nema31lebowski\n",
      "https://old.reddit.com/user/ogretronz\n",
      "https://old.reddit.com/user/saindoja\n",
      "https://old.reddit.com/user/yaakarsh1011\n",
      "https://old.reddit.com/user/saik2363\n",
      "https://old.reddit.com/user/VictorChen1\n",
      "https://old.reddit.com/user/MisterInvicta\n",
      "https://old.reddit.com/user/hyperxenophiliac\n",
      "https://old.reddit.com/user/TheLSales\n",
      "https://old.reddit.com/user/aznpersuazion\n",
      "https://old.reddit.com/user/kribz666\n",
      "https://old.reddit.com/user/fu11m3ta1\n",
      "https://old.reddit.com/user/kunal_packtpub\n"
     ]
    }
   ],
   "source": [
    "# profile link\n",
    "\n",
    "Author_Profile_Link =[]\n",
    "\n",
    "for post in posts[3:]:\n",
    "    author = post.find(\"a\", class_=\"author\",text=True)\n",
    "    Author_Profile_Link.append(author.get('href'))\n",
    "    print(author.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 4:** Extract the submission time of the retrieved posts and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 23 18:49:43 2021 UTC\n",
      "Fri Sep 17 17:00:55 2021 UTC\n",
      "Thu Sep 16 22:40:21 2021 UTC\n",
      "Thu Sep 9 11:50:16 2021 UTC\n",
      "Thu Aug 19 16:01:05 2021 UTC\n",
      "Tue Sep 7 15:43:32 2021 UTC\n",
      "Mon Sep 20 10:00:51 2021 UTC\n",
      "Mon Sep 6 16:57:19 2021 UTC\n",
      "Sat Sep 11 02:31:51 2021 UTC\n",
      "Wed Sep 22 03:03:33 2021 UTC\n",
      "Sat Sep 11 17:06:12 2021 UTC\n",
      "Mon Aug 16 19:18:19 2021 UTC\n",
      "Wed Aug 4 21:30:53 2021 UTC\n",
      "Fri Sep 17 14:11:21 2021 UTC\n",
      "Fri Sep 17 01:20:46 2021 UTC\n",
      "Tue Sep 21 18:05:12 2021 UTC\n",
      "Tue Sep 21 14:19:20 2021 UTC\n",
      "Tue Sep 14 13:05:59 2021 UTC\n",
      "Tue Jul 20 01:29:22 2021 UTC\n",
      "Sun Sep 19 20:49:43 2021 UTC\n",
      "Sun Sep 19 00:16:10 2021 UTC\n",
      "Fri Sep 24 09:30:56 2021 UTC\n"
     ]
    }
   ],
   "source": [
    "# time\n",
    "\n",
    "Submission_Time =[]\n",
    "\n",
    "\n",
    "for post in posts[3:]:\n",
    "    time = post.find(\"time\",text=True)\n",
    "    #print(time.text)\n",
    "    Submission_Time.append(time.get('title'))\n",
    "    print(time.get('title'))\n",
    "    #print(time.get('datetime'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 5:** Extract the subreddits of the retrieved posts and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/datascience\n",
      "r/datascience\n",
      "r/datascience\n",
      "r/datascience\n",
      "r/datascience\n",
      "r/learndatascience\n",
      "r/datascience\n",
      "r/datascience\n",
      "r/kpopthoughts\n",
      "r/wallstreetbets\n",
      "r/datascience\n",
      "r/datascience\n",
      "r/datascience\n",
      "r/datascience\n",
      "r/Notion\n",
      "r/canoo\n",
      "r/rstats\n",
      "r/AerospaceEngineering\n",
      "r/datascience\n",
      "r/smallstreetbets\n",
      "r/analytics\n",
      "r/learndatascience\n"
     ]
    }
   ],
   "source": [
    "# sub reddit\n",
    "\n",
    "Subreddit = []\n",
    "\n",
    "for post in posts[3:]:\n",
    "    subreddit = post.find(\"a\", class_=\"search-subreddit-link\",text=True)\n",
    "    Subreddit.append(subreddit.text)\n",
    "    print(subreddit.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 6:** Extract the associated tag(s) of the retrieved posts and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discussion\n",
      "Fun/Trivia\n",
      "Discussion\n",
      "Discussion\n",
      "Discussion\n",
      "Resources\n",
      "Discussion\n",
      "Discussion\n",
      "Boy Groups\n",
      "Discussion\n",
      "Discussion\n",
      "Career\n",
      "Networking\n",
      "Networking\n",
      "Showcase\n",
      "New Hires\n",
      "None\n",
      "Career\n",
      "Career\n",
      "Discussion\n",
      "Question\n",
      "Resources\n"
     ]
    }
   ],
   "source": [
    "# tags\n",
    "\n",
    "Tag = []\n",
    "\n",
    "for post in posts[3:]:\n",
    "    tag = post.find(\"span\", class_=\"linkflairlabel\",text=True)\n",
    "    if tag is None:\n",
    "        Tag.append('None')\n",
    "        print('None')\n",
    "    else:\n",
    "        Tag.append(tag.text)\n",
    "        print(tag.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 7:** Extract the points of the retrieved posts and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 points\n",
      "191 points\n",
      "109 points\n",
      "211 points\n",
      "1,217 points\n",
      "746 points\n",
      "68 points\n",
      "196 points\n",
      "183 points\n",
      "43 points\n",
      "53 points\n",
      "245 points\n",
      "334 points\n",
      "156 points\n",
      "165 points\n",
      "61 points\n",
      "24 points\n",
      "22 points\n",
      "681 points\n",
      "103 points\n",
      "31 points\n",
      "10 points\n"
     ]
    }
   ],
   "source": [
    "# points\n",
    "\n",
    "Points = []\n",
    "\n",
    "for post in posts[3:]:\n",
    "    points = post.find(\"span\", class_=\"search-score\",text=True)\n",
    "    Points.append(points.text)\n",
    "    print(points.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 8:** Extract the num of comments of the retrieved posts and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 comments\n",
      "119 comments\n",
      "128 comments\n",
      "158 comments\n",
      "156 comments\n",
      "54 comments\n",
      "53 comments\n",
      "95 comments\n",
      "50 comments\n",
      "31 comments\n",
      "63 comments\n",
      "152 comments\n",
      "238 comments\n",
      "19 comments\n",
      "17 comments\n",
      "17 comments\n",
      "28 comments\n",
      "40 comments\n",
      "302 comments\n",
      "12 comments\n",
      "24 comments\n",
      "20 comments\n"
     ]
    }
   ],
   "source": [
    "# comments\n",
    "\n",
    "Comments = []\n",
    "\n",
    "for post in posts[3:]:\n",
    "    comments = post.find(\"a\", class_=\"search-comments\",text=True)\n",
    "    Comments.append(comments.text)\n",
    "    print(comments.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 9:** Using the above nine features create a dataframe for the retrieved posts, and print the first 10 entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>Author_Profile_Link</th>\n",
       "      <th>Submission_Time</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Points</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data science even at mature companies can be a...</td>\n",
       "      <td>/r/datascience/comments/pu1y72/data_science_ev...</td>\n",
       "      <td>__compactsupport__</td>\n",
       "      <td>https://old.reddit.com/user/__compactsupport__</td>\n",
       "      <td>Thu Sep 23 18:49:43 2021 UTC</td>\n",
       "      <td>r/datascience</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>281 points</td>\n",
       "      <td>105 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who are your data science heroes?</td>\n",
       "      <td>/r/datascience/comments/pq44jp/who_are_your_da...</td>\n",
       "      <td>GravityAI</td>\n",
       "      <td>https://old.reddit.com/user/GravityAI</td>\n",
       "      <td>Fri Sep 17 17:00:55 2021 UTC</td>\n",
       "      <td>r/datascience</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>191 points</td>\n",
       "      <td>119 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>College Professor in Data Science Course Just ...</td>\n",
       "      <td>/r/datascience/comments/ppntvz/college_profess...</td>\n",
       "      <td>Illustrious_Ice_5022</td>\n",
       "      <td>https://old.reddit.com/user/Illustrious_Ice_5022</td>\n",
       "      <td>Thu Sep 16 22:40:21 2021 UTC</td>\n",
       "      <td>r/datascience</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>109 points</td>\n",
       "      <td>128 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you use OOP in your daily data science work?</td>\n",
       "      <td>/r/datascience/comments/pkw92b/do_you_use_oop_...</td>\n",
       "      <td>rightheart</td>\n",
       "      <td>https://old.reddit.com/user/rightheart</td>\n",
       "      <td>Thu Sep 9 11:50:16 2021 UTC</td>\n",
       "      <td>r/datascience</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>211 points</td>\n",
       "      <td>158 comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Key Word in Data Science is Science, not Data</td>\n",
       "      <td>/r/datascience/comments/p7hpd9/the_key_word_in...</td>\n",
       "      <td>yoi12321</td>\n",
       "      <td>https://old.reddit.com/user/yoi12321</td>\n",
       "      <td>Thu Aug 19 16:01:05 2021 UTC</td>\n",
       "      <td>r/datascience</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>1,217 points</td>\n",
       "      <td>156 comments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data science even at mature companies can be a...   \n",
       "1                  Who are your data science heroes?   \n",
       "2  College Professor in Data Science Course Just ...   \n",
       "3    Do you use OOP in your daily data science work?   \n",
       "4  The Key Word in Data Science is Science, not Data   \n",
       "\n",
       "                                                 URL                Author  \\\n",
       "0  /r/datascience/comments/pu1y72/data_science_ev...    __compactsupport__   \n",
       "1  /r/datascience/comments/pq44jp/who_are_your_da...             GravityAI   \n",
       "2  /r/datascience/comments/ppntvz/college_profess...  Illustrious_Ice_5022   \n",
       "3  /r/datascience/comments/pkw92b/do_you_use_oop_...            rightheart   \n",
       "4  /r/datascience/comments/p7hpd9/the_key_word_in...              yoi12321   \n",
       "\n",
       "                                Author_Profile_Link  \\\n",
       "0    https://old.reddit.com/user/__compactsupport__   \n",
       "1             https://old.reddit.com/user/GravityAI   \n",
       "2  https://old.reddit.com/user/Illustrious_Ice_5022   \n",
       "3            https://old.reddit.com/user/rightheart   \n",
       "4              https://old.reddit.com/user/yoi12321   \n",
       "\n",
       "                Submission_Time      Subreddit         Tag        Points  \\\n",
       "0  Thu Sep 23 18:49:43 2021 UTC  r/datascience  Discussion    281 points   \n",
       "1  Fri Sep 17 17:00:55 2021 UTC  r/datascience  Fun/Trivia    191 points   \n",
       "2  Thu Sep 16 22:40:21 2021 UTC  r/datascience  Discussion    109 points   \n",
       "3   Thu Sep 9 11:50:16 2021 UTC  r/datascience  Discussion    211 points   \n",
       "4  Thu Aug 19 16:01:05 2021 UTC  r/datascience  Discussion  1,217 points   \n",
       "\n",
       "       Comments  \n",
       "0  105 comments  \n",
       "1  119 comments  \n",
       "2  128 comments  \n",
       "3  158 comments  \n",
       "4  156 comments  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I appended lists in each of the above sections. Combining here for Data Frame\n",
    "\n",
    "Reddit_DF = pd.DataFrame({\n",
    "    'Title': Title,\n",
    "    'URL': URL,\n",
    "    'Author': Author,\n",
    "    'Author_Profile_Link': Author_Profile_Link,\n",
    "    'Submission_Time': Submission_Time,\n",
    "    'Subreddit': Subreddit,\n",
    "    'Tag': Tag,\n",
    "    'Points': Points,\n",
    "    'Comments': Comments\n",
    "})\n",
    "\n",
    "Reddit_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 10:** Save the retrieved posts in a json file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the entire dataframe as a json file\n",
    "\n",
    "Reddit_DF.to_json('LCM_Reddit_DF.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
